{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDlR0lFGktqW",
        "outputId": "7a4ee2f9-c85d-4c5b-9c7b-1a61a1f139db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… å·²å®Œæˆç‰¹å¾æ ‡å‡†åŒ–ï¼ˆå‡å€¼â‰ˆ0ï¼Œæ–¹å·®â‰ˆ1ï¼‰\n",
            "âœ… Loaded 140523 samples from 3840 files.\n",
            "ğŸ•’ timeåˆ—å­˜åœ¨äº 3840 ä¸ªæ–‡ä»¶ï¼Œç¼ºå¤± 0 ä¸ªæ–‡ä»¶ã€‚\n",
            "\n",
            "ğŸ“Š æ•°æ®é›†æ€»ä½“ä¿¡æ¯:\n",
            "                         count unique  top freq  \\\n",
            "time                    140523    NaN  NaN  NaN   \n",
            "temperature_2m        140523.0    NaN  NaN  NaN   \n",
            "relative_humidity_2m  140523.0    NaN  NaN  NaN   \n",
            "surface_pressure      140523.0    NaN  NaN  NaN   \n",
            "wind_speed_10m        140523.0    NaN  NaN  NaN   \n",
            "wind_direction_10m    140523.0    NaN  NaN  NaN   \n",
            "cloud_cover           140523.0    NaN  NaN  NaN   \n",
            "precipitation         140523.0    NaN  NaN  NaN   \n",
            "hour                  140523.0    NaN  NaN  NaN   \n",
            "month                 140523.0    NaN  NaN  NaN   \n",
            "\n",
            "                                               mean                  min  \\\n",
            "time                  2020-01-18 20:16:13.403642368  2015-01-01 10:00:00   \n",
            "temperature_2m                                  0.0            -6.317824   \n",
            "relative_humidity_2m                           -0.0            -4.359904   \n",
            "surface_pressure                               -0.0            -3.540549   \n",
            "wind_speed_10m                                 -0.0            -1.616816   \n",
            "wind_direction_10m                              0.0            -1.795554   \n",
            "cloud_cover                                     0.0            -2.222053   \n",
            "precipitation                              1.437106                  0.0   \n",
            "hour                                           -0.0            -1.509772   \n",
            "month                                          -0.0            -1.662974   \n",
            "\n",
            "                                      25%                  50%  \\\n",
            "time                  2017-07-14 23:00:00  2020-02-09 19:00:00   \n",
            "temperature_2m                  -0.647591             0.138382   \n",
            "relative_humidity_2m            -0.380573             0.311485   \n",
            "surface_pressure                 0.179233              0.40701   \n",
            "wind_speed_10m                   -0.73773             -0.20787   \n",
            "wind_direction_10m              -0.860144             0.065316   \n",
            "cloud_cover                     -0.486729             0.641231   \n",
            "precipitation                         0.0                  0.3   \n",
            "hour                            -0.788202            -0.066632   \n",
            "month                           -0.772864             0.117245   \n",
            "\n",
            "                                      75%                  max       std  \n",
            "time                  2022-07-18 12:00:00  2024-12-31 20:00:00       NaN  \n",
            "temperature_2m                   0.800845             3.068938       1.0  \n",
            "relative_humidity_2m             0.715185             1.176557       1.0  \n",
            "surface_pressure                 0.496065             1.093765       1.0  \n",
            "wind_speed_10m                   0.526709            10.088277       1.0  \n",
            "wind_direction_10m               0.761898             1.786869       1.0  \n",
            "cloud_cover                      0.670153             0.670153       1.0  \n",
            "precipitation                         1.4                 31.3  2.893858  \n",
            "hour                             0.799251             1.809449       1.0  \n",
            "month                            0.710651             1.600761       1.0  \n",
            "\n",
            "ğŸŒ§ï¸ å„é›¨é‡åŒºé—´æ ·æœ¬æ•°é‡:\n",
            "rain_bin\n",
            "none        51277\n",
            "light       46122\n",
            "moderate    28504\n",
            "heavy       14080\n",
            "extreme       540\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ğŸŒ¡ï¸ ç‰¹å¾åˆ—ç¤ºä¾‹:\n",
            "['temperature_2m', 'relative_humidity_2m', 'surface_pressure', 'wind_speed_10m', 'wind_direction_10m', 'cloud_cover', 'hour', 'month', 'hour_sin', 'hour_cos']\n",
            "\n",
            "ğŸ” éšæœºæŸ¥çœ‹éƒ¨åˆ†æ ·æœ¬:\n",
            "        precipitation  rain_bin  temperature_2m  relative_humidity_2m  \\\n",
            "90679             0.2     light       -1.354967             -0.438244   \n",
            "29286             2.2  moderate        1.059093             -0.034544   \n",
            "100339            0.0      none       -0.198464             -0.438244   \n",
            "75286             0.0      none       -0.254605             -0.553587   \n",
            "66421             0.0      none       -2.466557              0.138471   \n",
            "\n",
            "        surface_pressure  wind_speed_10m  wind_direction_10m  \n",
            "90679           0.305966       -0.460758           -0.700925  \n",
            "29286           0.441262       -1.219421            1.299261  \n",
            "100339          0.653625       -0.003151            0.652435  \n",
            "75286          -2.415366       -0.966533           -0.860144  \n",
            "66421          -0.130749       -0.027236            1.239554  \n",
            "Series([], dtype: object)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "RAW_DIR = \"./dataset_global/raw_hourly\"\n",
        "\n",
        "class WeatherDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ä» parquet è¯»å–å¤©æ°”æ ·æœ¬ï¼ŒæŒ‰é›¨é‡åˆ†æ®µåšé‡é‡‡æ ·ï¼›æ”¯æŒä¸‹é‡‡æ ·ä¸è·³æ ·ä»¥æ§åˆ¶ä½“ç§¯ã€‚\n",
        "    è®­ç»ƒè„šæœ¬ä¸­ä¼šå¯¹ features åšæ ‡å‡†åŒ–ï¼Œå¯¹ç›®æ ‡åš log1p å˜æ¢ã€‚\n",
        "    è‡ªåŠ¨æ£€æµ‹å¹¶ä¿®å¤ç¼ºå¤± time åˆ—çš„æ–‡ä»¶ã€‚\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        root=RAW_DIR,\n",
        "        sample_frac=0.2,\n",
        "        skip_rate=3,\n",
        "        bin_weights=None,\n",
        "        random_state=42\n",
        "    ):\n",
        "        self.files = sorted(glob.glob(os.path.join(root, \"*.parquet\")))\n",
        "        if not self.files:\n",
        "            raise RuntimeError(f\"æœªåœ¨ {root} æ‰¾åˆ° parquet æ–‡ä»¶ã€‚\")\n",
        "\n",
        "        self.sample_frac = sample_frac\n",
        "        self.skip_rate = skip_rate\n",
        "        self.random_state = random_state\n",
        "        self.time_ok = 0\n",
        "        self.time_missing = 0\n",
        "\n",
        "        if bin_weights is None:\n",
        "            bin_weights = {\"none\": 1, \"light\": 10, \"moderate\": 20, \"heavy\": 100, \"extreme\": 300}\n",
        "        self.bin_weights = bin_weights\n",
        "\n",
        "        parts = []\n",
        "        for f in self.files:\n",
        "            try:\n",
        "                df = pd.read_parquet(f)\n",
        "                if df.empty:\n",
        "                    continue\n",
        "\n",
        "                # å°è¯•æ¢å¤æ—¶é—´åˆ—ï¼ˆå¯èƒ½æ˜¯ indexï¼‰\n",
        "                if \"time\" not in df.columns and isinstance(df.index, pd.DatetimeIndex):\n",
        "                    df = df.reset_index().rename(columns={\"index\": \"time\"})\n",
        "\n",
        "                # è‹¥ä»ç„¶æ²¡æœ‰ timeï¼Œåˆ™æ ¹æ®æ–‡ä»¶åæ¨æ–­\n",
        "                if \"time\" not in df.columns:\n",
        "                    m = re.search(r\"_(\\d{4}-\\d{2}-\\d{2})_(\\d{4}-\\d{2}-\\d{2})\\.parquet$\", f)\n",
        "                    if m:\n",
        "                        start = pd.to_datetime(m.group(1))\n",
        "                        end = pd.to_datetime(m.group(2))\n",
        "                        n = len(df)\n",
        "                        df[\"time\"] = pd.date_range(start, periods=n, freq=\"H\")\n",
        "                    else:\n",
        "                        df[\"time\"] = pd.NaT\n",
        "\n",
        "                if df[\"time\"].isna().all():\n",
        "                    self.time_missing += 1\n",
        "                else:\n",
        "                    self.time_ok += 1\n",
        "\n",
        "                # ä¸‹é‡‡æ ·ï¼ˆæ¯ä¸ªæ–‡ä»¶ï¼‰\n",
        "                df = df.sample(frac=self.sample_frac, random_state=self.random_state)\n",
        "\n",
        "                # æ—¶é—´å­—æ®µå±•å¼€\n",
        "                t = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
        "                df[\"hour\"] = t.dt.hour.fillna(0).astype(int)\n",
        "                df[\"month\"] = t.dt.month.fillna(1).astype(int)\n",
        "\n",
        "               \n",
        "                df[\"hour_sin\"] = np.sin(2*np.pi*df[\"hour\"]/24)\n",
        "                df[\"hour_cos\"] = np.cos(2*np.pi*df[\"hour\"]/24)\n",
        "                df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12)\n",
        "                df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
        "\n",
        "                # é›¨é‡åˆ†ç®±\n",
        "                bins = [-0.1, 0.1, 1.0, 5.0, 20.0, np.inf]\n",
        "                labels = [\"none\", \"light\", \"moderate\", \"heavy\", \"extreme\"]\n",
        "                df[\"rain_bin\"] = pd.cut(df[\"precipitation\"], bins=bins, labels=labels)\n",
        "\n",
        "                # é‡é‡‡æ ·\n",
        "                resampled = []\n",
        "                for level in labels:\n",
        "                    grp = df[df[\"rain_bin\"] == level]\n",
        "                    if len(grp) == 0:\n",
        "                        continue\n",
        "                    w = self.bin_weights.get(level, 1)\n",
        "                    n = max(1, int(len(grp) * w))\n",
        "                    resampled.append(grp.sample(n=n, replace=True, random_state=self.random_state))\n",
        "                if not resampled:\n",
        "                    continue\n",
        "\n",
        "                merged = pd.concat(resampled, ignore_index=True)\n",
        "                merged = merged.iloc[::self.skip_rate, :]\n",
        "                parts.append(merged)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ è·³è¿‡ {f}: {e}\")\n",
        "\n",
        "        if not parts:\n",
        "            raise RuntimeError(\"æ²¡æœ‰æ„å»ºå‡ºæœ‰æ•ˆæ ·æœ¬ã€‚\")\n",
        "\n",
        "        self.data = pd.concat(parts, ignore_index=True).reset_index(drop=True)\n",
        "        drop_cols = {\"precipitation\", \"rain_bin\", \"time\"}\n",
        "        self.features = [c for c in self.data.columns if c not in drop_cols]\n",
        "        self.mean = self.data[self.features].mean()\n",
        "        self.std = self.data[self.features].std().replace(0, 1e-6)\n",
        "        self.data[self.features] = (self.data[self.features] - self.mean) / (self.std + 1e-6)\n",
        "        print(\"âœ… å·²å®Œæˆç‰¹å¾æ ‡å‡†åŒ–ï¼ˆå‡å€¼â‰ˆ0ï¼Œæ–¹å·®â‰ˆ1ï¼‰\")\n",
        "\n",
        "\n",
        "        print(f\"âœ… Loaded {len(self.data)} samples from {len(self.files)} files.\")\n",
        "        print(f\"ğŸ•’ timeåˆ—å­˜åœ¨äº {self.time_ok} ä¸ªæ–‡ä»¶ï¼Œç¼ºå¤± {self.time_missing} ä¸ªæ–‡ä»¶ã€‚\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        # âœ… å®‰å…¨è½¬æ¢ä¸º float32ï¼Œå¿½ç•¥éæ³•å€¼\n",
        "        x = torch.tensor(row[self.features].astype(float).values, dtype=torch.float32)\n",
        "        y = torch.tensor(float(row[\"precipitation\"]), dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "\n",
        "# ---------------- main é¢„è§ˆéƒ¨åˆ† ---------------- #\n",
        "if __name__ == \"__main__\":\n",
        "    ds = WeatherDataset(sample_frac=0.1, skip_rate=5)\n",
        "    df = ds.data\n",
        "\n",
        "    print(\"\\nğŸ“Š æ•°æ®é›†æ€»ä½“ä¿¡æ¯:\")\n",
        "    print(df.describe(include='all').transpose().head(10))\n",
        "\n",
        "    print(\"\\nğŸŒ§ï¸ å„é›¨é‡åŒºé—´æ ·æœ¬æ•°é‡:\")\n",
        "    print(df[\"rain_bin\"].value_counts().sort_index())\n",
        "\n",
        "    print(\"\\nğŸŒ¡ï¸ ç‰¹å¾åˆ—ç¤ºä¾‹:\")\n",
        "    print(ds.features[:10])\n",
        "\n",
        "    print(\"\\nğŸ” éšæœºæŸ¥çœ‹éƒ¨åˆ†æ ·æœ¬:\")\n",
        "    print(df.sample(5, random_state=0)[[\"precipitation\", \"rain_bin\"] + ds.features[:5]])\n",
        "    print(ds.data.dtypes[ds.data.dtypes == 'object'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-1lb-3qkz8G",
        "outputId": "8ade7cde-6042-4198-944f-504423c07d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§  ä½¿ç”¨è®¾å¤‡: mps\n",
            "âœ… å·²å®Œæˆç‰¹å¾æ ‡å‡†åŒ–ï¼ˆå‡å€¼â‰ˆ0ï¼Œæ–¹å·®â‰ˆ1ï¼‰\n",
            "âœ… Loaded 352367 samples from 3840 files.\n",
            "ğŸ•’ timeåˆ—å­˜åœ¨äº 3840 ä¸ªæ–‡ä»¶ï¼Œç¼ºå¤± 0 ä¸ªæ–‡ä»¶ã€‚\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1102/1102 [02:22<00:00,  7.72batch/s]\n",
            "Epoch 1/10 [val]:   0%|          | 0/276 [00:00<?, ?batch/s]Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/yangliu/miniforge3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/yangliu/miniforge3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'SequenceWrapper' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
            "Epoch 1/10 [val]:   0%|          | 0/276 [02:04<?, ?batch/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 288\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# åˆå§‹åŒ–æ¨¡å‹\u001b[39;00m\n\u001b[32m    287\u001b[39m model = RainfallTransformer(input_dim=\u001b[38;5;28mlen\u001b[39m(feature_cols), seq_len=seq_len)\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m history, final_model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# åŠ è½½æœ€ä¼˜æ¨¡å‹\u001b[39;00m\n\u001b[32m    291\u001b[39m best = RainfallTransformer(input_dim=\u001b[38;5;28mlen\u001b[39m(feature_cols), seq_len=seq_len).to(device)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 184\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, device, epochs, base_lr, use_ema)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    183\u001b[39m     eval_model = ema_model \u001b[38;5;28;01mif\u001b[39;00m (use_ema \u001b[38;5;129;01mand\u001b[39;00m epoch > \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m model\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m [val]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43myb_log\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog1p\u001b[49m\u001b[43m(\u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:493\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:424\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1171\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1164\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# âš™ï¸ æ•°æ®åŒ…è£…å™¨ï¼šå°† WeatherDataset è½¬ä¸ºæ—¶é—´åºåˆ—æ ·æœ¬\n",
        "# =========================================================\n",
        "class SequenceWrapper(Dataset):\n",
        "    \"\"\"å°† WeatherDataset è½¬æ¢ä¸º [seq_len â†’ é¢„æµ‹ä¸‹ä¸€æ­¥] æ ·æœ¬\"\"\"\n",
        "    def __init__(self, base_ds: WeatherDataset, seq_len=24):\n",
        "        self.base = base_ds\n",
        "        self.seq_len = seq_len\n",
        "        self.df = base_ds.data.sort_values(\"time\").reset_index(drop=True)\n",
        "        self.features = base_ds.features\n",
        "        self.values = self.df[self.features].values.astype(np.float32)\n",
        "        self.targets = self.df[\"precipitation\"].values.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.values[idx:idx + self.seq_len]\n",
        "        y = self.targets[idx + self.seq_len]\n",
        "        return torch.tensor(x), torch.tensor(y)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# ğŸ§  Transformer æ¨¡å‹\n",
        "# =========================================================\n",
        "class RainfallTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, seq_len=24, d_model=256, nhead=8, num_layers=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, d_model))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=4 * d_model,\n",
        "            dropout=dropout,\n",
        "            activation=\"gelu\",\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Linear(d_model, 256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, seq_len, input_dim]\n",
        "        x_proj = self.input_proj(x) + self.pos_embedding[:, :x.size(1)]\n",
        "        enc = self.encoder(x_proj)                # [B, seq_len, D]\n",
        "        pooled = enc.mean(dim=1)                  # å¹³å‡æ± åŒ–\n",
        "        out = self.head(pooled).squeeze(-1)\n",
        "        return out\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# è®­ç»ƒç›¸å…³å·¥å…·\n",
        "# =========================================================\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    print(f\"ğŸ§  ä½¿ç”¨è®¾å¤‡: {device}\")\n",
        "    return device\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=6, min_delta=1e-4):\n",
        "        self.best = float(\"inf\")\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.stop = False\n",
        "\n",
        "    def step(self, v):\n",
        "        if v < self.best - self.min_delta:\n",
        "            self.best = v\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.stop = True\n",
        "\n",
        "\n",
        "def plot_loss(history, out=\"loss_curve.png\"):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(history[\"train\"], label=\"Train Loss\", marker=\"o\")\n",
        "    plt.plot(history[\"val\"], label=\"Val Loss\", marker=\"s\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Huber Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
        "    plt.savefig(out, dpi=150); plt.close()\n",
        "    print(f\"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜ä¸º {out}\")\n",
        "\n",
        "\n",
        "def scatter_with_error(trues, preds, out=\"pred_vs_true_colored.png\"):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    errors = preds - trues\n",
        "    sc = plt.scatter(trues, preds, c=errors, cmap=\"coolwarm\", s=8, alpha=0.7)\n",
        "    lim = max(trues.max(), preds.max())\n",
        "    plt.plot([0, lim], [0, lim], \"k--\", lw=1)\n",
        "    plt.colorbar(sc, label=\"Pred - True (log1p)\")\n",
        "    plt.xlabel(\"True Precipitation (log1p)\")\n",
        "    plt.ylabel(\"Predicted (log1p)\")\n",
        "    plt.title(\"Prediction vs Actual (Color = Error)\")\n",
        "    plt.grid(True); plt.tight_layout()\n",
        "    plt.savefig(out, dpi=150); plt.close()\n",
        "    print(f\"ğŸ“ˆ é¢„æµ‹æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º {out}\")\n",
        "\n",
        "\n",
        "def compute_metrics(trues, preds):\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    mae = mean_absolute_error(trues, preds)\n",
        "    r2 = r2_score(trues, preds)\n",
        "    return rmse, mae, r2\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# ğŸ‹ï¸â€â™‚ï¸ è®­ç»ƒä¸»å¾ªç¯\n",
        "# =========================================================\n",
        "def train_model(model, train_loader, val_loader, device, epochs=50, base_lr=5e-4, use_ema=True):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.HuberLoss(delta=0.1)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=base_lr, weight_decay=1e-3)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=base_lr * 5.0, epochs=epochs, steps_per_epoch=len(train_loader)\n",
        "    )\n",
        "\n",
        "    ema_model = deepcopy(model) if use_ema else None\n",
        "    ema_decay = 0.999\n",
        "    best_val = float(\"inf\")\n",
        "    history = {\"train\": [], \"val\": []}\n",
        "    early_stop = EarlyStopping(patience=6, min_delta=1e-4)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # ---- train ----\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} [train]\", unit=\"batch\"):\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            yb_log = torch.log1p(yb)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb_log)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            if use_ema:\n",
        "                with torch.no_grad():\n",
        "                    for p, ep in zip(model.parameters(), ema_model.parameters()):\n",
        "                        ep.data.mul_(ema_decay).add_(p.data, alpha=1 - ema_decay)\n",
        "            total += loss.item() * len(xb)\n",
        "\n",
        "        train_loss = total / len(train_loader.dataset)\n",
        "        history[\"train\"].append(train_loss)\n",
        "\n",
        "        # ---- val ----\n",
        "        model.eval()\n",
        "        val_total = 0.0\n",
        "        preds_all, trues_all = [], []\n",
        "        with torch.no_grad():\n",
        "            eval_model = ema_model if (use_ema and epoch > 1) else model\n",
        "            for xb, yb in tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} [val]\", unit=\"batch\"):\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                yb_log = torch.log1p(yb)\n",
        "                pred = eval_model(xb)\n",
        "                val_total += criterion(pred, yb_log).item() * len(xb)\n",
        "                preds_all.append(pred.detach().cpu())\n",
        "                trues_all.append(yb_log.detach().cpu())\n",
        "\n",
        "        val_loss = val_total / len(val_loader.dataset)\n",
        "        history[\"val\"].append(val_loss)\n",
        "\n",
        "        preds_np = torch.cat(preds_all).numpy()\n",
        "        trues_np = torch.cat(trues_all).numpy()\n",
        "        rmse, mae, r2 = compute_metrics(trues_np, preds_np)\n",
        "        print(f\"ğŸ“‰ Epoch {epoch:>2} | Train {train_loss:.6f} | Val {val_loss:.6f} | RMSE {rmse:.4f} | MAE {mae:.4f} | RÂ² {r2:.4f}\")\n",
        "\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            torch.save((ema_model if (use_ema and epoch > 1) else model).state_dict(), \"checkpoint_best.pt\")\n",
        "            print(f\"ğŸ’¾ æ–°æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (val_loss={val_loss:.6f})\")\n",
        "\n",
        "        early_stop.step(val_loss)\n",
        "        if early_stop.stop:\n",
        "            print(f\"â¹ï¸ Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    plot_loss(history)\n",
        "    return history, (ema_model if use_ema else model)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# ğŸ“Š éªŒè¯é›†å¯è§†åŒ–\n",
        "# =========================================================\n",
        "def visualize_on_val(model, val_loader, device):\n",
        "    import numpy as np\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device)\n",
        "            pred = model(xb)\n",
        "            preds.append(pred.cpu())\n",
        "            trues.append(torch.log1p(yb).cpu())  # log ç©ºé—´è¯„ä¼°\n",
        "    preds = torch.cat(preds).numpy()\n",
        "    trues = torch.cat(trues).numpy()\n",
        "\n",
        "    # ---------- log ç©ºé—´ ----------\n",
        "    rmse, mae, r2 = compute_metrics(trues, preds)\n",
        "    print(f\"ğŸ” Final (Val, log space) â†’ RMSE={rmse:.4f}, MAE={mae:.4f}, RÂ²={r2:.4f}\")\n",
        "    scatter_with_error(trues, preds, out=\"pred_vs_true_colored.png\")\n",
        "\n",
        "    # ---------- è½¬å› mm/h ç©ºé—´ ----------\n",
        "    preds_lin = np.expm1(preds)\n",
        "    trues_lin = np.expm1(trues)\n",
        "    rmse_lin, mae_lin, r2_lin = compute_metrics(trues_lin, preds_lin)\n",
        "    print(f\"ğŸŒ§ï¸  (Val, mm/h) â†’ RMSE={rmse_lin:.4f}, MAE={mae_lin:.4f}, RÂ²={r2_lin:.4f}\")\n",
        "\n",
        "    # ---------- ç»˜åˆ¶çº¿æ€§ç©ºé—´æ•£ç‚¹ ----------\n",
        "    plt.figure(figsize=(6,6))\n",
        "    errors = preds_lin - trues_lin\n",
        "    sc = plt.scatter(trues_lin, preds_lin, c=errors, cmap=\"coolwarm\", s=8, alpha=0.7)\n",
        "    lim = max(trues_lin.max(), preds_lin.max()) * 1.05\n",
        "    plt.plot([0, lim], [0, lim], \"k--\", lw=1)\n",
        "    plt.xscale(\"log\"); plt.yscale(\"log\")\n",
        "    plt.colorbar(sc, label=\"Pred - True (mm/h)\")\n",
        "    plt.xlabel(\"True Precipitation (mm/h)\")\n",
        "    plt.ylabel(\"Predicted (mm/h)\")\n",
        "    plt.title(\"Prediction vs Actual (Color = Error, log-log scale)\")\n",
        "    plt.grid(True, which=\"both\", ls=\"--\", lw=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"pred_vs_true_real_mm.png\", dpi=150)\n",
        "    plt.close()\n",
        "    print(\"ğŸ“ˆ å·²ä¿å­˜çœŸå®å•ä½ç©ºé—´æ•£ç‚¹å›¾ï¼špred_vs_true_real_mm.png\")\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# main\n",
        "# =========================================================\n",
        "if __name__ == \"__main__\":\n",
        "    device = get_device()\n",
        "\n",
        "    base_ds = WeatherDataset(sample_frac=0.15, skip_rate=3)\n",
        "    feature_cols = base_ds.features\n",
        "\n",
        "    # âš™ï¸ æ ‡å‡†åŒ–\n",
        "    base_ds.mean = base_ds.data[feature_cols].mean()\n",
        "    base_ds.std = base_ds.data[feature_cols].std().replace(0, 1)\n",
        "    base_ds.data[feature_cols] = (base_ds.data[feature_cols] - base_ds.mean) / (base_ds.std + 1e-6)\n",
        "\n",
        "    # æ„å»ºæ—¶é—´åºåˆ—æ ·æœ¬\n",
        "    seq_len = 24\n",
        "    ds_seq = SequenceWrapper(base_ds, seq_len=seq_len)\n",
        "\n",
        "    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯\n",
        "    val_size = int(0.2 * len(ds_seq))\n",
        "    train_size = len(ds_seq) - val_size\n",
        "    train_ds, val_ds = random_split(ds_seq, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=0, pin_memory=False)\n",
        "    val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=False)\n",
        "\n",
        "    # åˆå§‹åŒ–æ¨¡å‹\n",
        "    model = RainfallTransformer(input_dim=len(feature_cols), seq_len=seq_len)\n",
        "    history, final_model = train_model(model, train_loader, val_loader, device, epochs=10, base_lr=1e-5, use_ema=True)\n",
        "\n",
        "    # åŠ è½½æœ€ä¼˜æ¨¡å‹\n",
        "    best = RainfallTransformer(input_dim=len(feature_cols), seq_len=seq_len).to(device)\n",
        "    best.load_state_dict(torch.load(\"checkpoint_best.pt\", map_location=device))\n",
        "    best.eval()\n",
        "\n",
        "    visualize_on_val(best, val_loader, device)\n",
        "    print(\"âœ… è®­ç»ƒä¸è¯„ä¼°å®Œæˆã€‚æœ€ä¼˜æƒé‡: checkpoint_best.pt\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
